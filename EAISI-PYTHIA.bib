
@book{blokdyk_scor_2019,
	address = {[S.l.]},
	title = {{SCOR} {MODEL} {A} {COMPLETE} {GUIDE} - 2020 {EDITION}},
	isbn = {978-0-655-96649-4},
	language = {eng},
	publisher = {5STARCOOKS},
	author = {BLOKDYK, GERARDUS},
	year = {2019},
	note = {OCLC: 1412189016},
}

@book{costa_crisp-ml_2022,
	title = {The {CRISP}-{ML} {Methodology}: {A} {Step}-by-{Step} {Approach} to {Real}-{World} {Machine} {Learning} {Projects}},
	isbn = {9798371647122},
	shorttitle = {{CRISP}-{DM}},
	language = {English},
	publisher = {Independently published},
	author = {Costa, R},
	year = {2022},
}

@book{guja_generative_2025,
	title = {Generative {AI} for {Data} {Analytics}.},
	isbn = {978-1-63343-721-0},
	language = {eng},
	publisher = {Manning Publications Co. LLC 2025.},
	author = {Guja, Artur and Siwiak, Marlena},
	year = {2025},
	note = {OCLC: 1437291469},
}

@book{hartshorn_machine_2017,
	title = {Machine {Learning} {With} {Boosting}: {A} {Beginner}'s {Guide}},
	shorttitle = {Machine {Learning} {With} {Boosting}},
	abstract = {Machine Learning - Made Easy To UnderstandIf you are looking for a book to help you understand how the machine learning algorithm “Gradient Boosted Trees”, also known as “Boosting”, works behind the scenes, then this is a good book for you.  Boosting is a widely used algorithm in a variety of applications, including big data analysis for industry and data analysis competitions like you would find on Kaggle.  Boosting has, in fact, become one of the dominant winning algorithms on Kaggle.This book explains how Decision Trees work and how they can be used sequentially to reduce many of the common problems with decision trees, such as overfitting the training data.  That method is known is Gradient Boosted Trees.Is This Book Any Good? Try A Free SampleIf you're reading this book description, you are probably already interested in Machine Learning, and know that Boosting is a useful topic. So the biggest question you have is, is the book good and will it be useful for you. Reviews are one way of determining that, but what was a good or bad read for someone else might be different for you. Fortunaltely Amazon makes a free sample available, and I also have a free sample available on my blog "Fairly Nerdy". Both of those samples are approximately 10\% of the book which is hopefully enough to help you decide if this is a good book for you. The sample on my blog is the first 10\% of the book, I think that Amazon sometimes sends the first 10\%, or sometimes sends other sections. You can get the Amazon sample by clicking "Send a free sample" on the right side of this page. You can get the free PDF sample by going to my blog "Fairly Nerdy" and clicking on the "Our Books" tab at the top of the page. (This book is about halfway down on that page) The nice thing about the sample is that it will be a fast read and give you a good high level understanding of Boosting even if you decide you don't want to dig into the details in the rest of the bookSeveral Dozen Visual ExamplesEquations are great for really understanding every last detail of an algorithm.  But to get a basic idea of how something works, in a way that will stick with you 6 months later, nothing beats pictures.  This book contains several dozen images which detail things such as how a decision tree picks what splits it will make and how they can be combined using boosted learning.Python \& Excel Files For The Examples It turns out that Boosting lends itself well to being done iteratively in Excel.  And the nice thing about Excel is that it is easy to follow the equations. And if your spreadsheet can duplicate your code, then you know that you understand the process.  All of the Boosting examples in this book were generated using Python, but then duplicated in Excel, both of which are available for free download.Topics CoveredThe topics covered in this book areHow do decision trees workWhat are some of the failings of decision trees, and where do they differ from how a human would solve the problemHow can multiple decision trees be stacked together into Gradient Boosted TreesHow to use the Boosting algorithm to make predictionsHow is the Boosting algorithm different for regression vs. classification with two categories vs. classification with multiple categoriesHow to use Cross Validation to check your modelHow to use Feature Engineering to improve the results from the machine learning algorithmAnd MoreIf you want to know more about how these machine learning algorithms work, but don't need to reinvent them, this is a good book for you},
	language = {English},
	author = {Hartshorn, Scott},
	month = aug,
	year = {2017},
}

@book{hyndman_forecasting_2021,
	title = {Forecasting: {Principles} and {Practice} (3rd ed)},
	shorttitle = {Forecasting},
	url = {https://otexts.com/fpp3/},
	abstract = {This textbook is intended to provide a comprehensive introduction to forecasting methods and to present enough information about each method for readers to be able to use them sensibly. We don’t attempt to give a thorough discussion of the theoretical details behind each method, although the references at the end of each chapter will fill in many of those details.

The book is written for three audiences: (1) people finding themselves doing forecasting in business when they may not have had any formal training in the area; (2) undergraduate students studying business; (3) MBA students doing a forecasting elective. We use it ourselves for masters students and third-year undergraduate students at Monash University, Australia.},
	language = {English},
	urldate = {2024-10-05},
	author = {Hyndman, R.J. and Athanasopoulos, G},
	year = {2021},
	note = {Melbourne, Australia},
}

@book{kunapuli_ensemble_2023,
	address = {Shelter Island, NY},
	title = {Ensemble methods for machine learning},
	isbn = {978-1-61729-713-7},
	language = {eng},
	publisher = {Manning},
	author = {Kunapuli, Gautam},
	year = {2023},
}

@book{manokhin_practical_2023,
	address = {Birmingham Mumbai},
	title = {Practical guide to applied conformal prediction in {Python}: learn and apply the best uncertainty frameworks to your industry applications},
	isbn = {978-1-80512-276-0},
	shorttitle = {Practical guide to applied conformal prediction in {Python}},
	abstract = {Discover the power of Conformal Prediction with the "Practical Guide to Applied Conformal Prediction in Python." Master the latest techniques to quantify uncertainty in machine learning and computer vision models, and seamlessly apply them to your industry applications},
	language = {eng},
	publisher = {{\textless}packt{\textgreater}},
	author = {Manokhin, Valery},
	year = {2023},
}

@book{molnar_introduction_2023,
	address = {München, Germany},
	edition = {First edition},
	title = {Introduction to conformal prediction with {Python}: a short guide for quantifying uncertainty of machine learning models},
	isbn = {9798377509356},
	shorttitle = {Introduction to conformal prediction with {Python}},
	url = {https://christophmolnar.com/books/conformal-prediction/},
	language = {eng},
	publisher = {Chistoph Molnar c/o MUCBOOK, Heidi Seibold},
	author = {Molnar, Christoph},
	year = {2023},
}

@misc{osullivan_introduction_2023,
	title = {Introduction to {SHAP} with {Python}},
	shorttitle = {{SHAP} with {Python}},
	url = {https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454},
	journal = {Introduction to SHAP with Python},
	author = {O'Sullivan, Conor},
	month = mar,
	year = {2023},
}

@misc{osullivan_shap_2024,
	type = {course},
	title = {{SHAP} with {Python}},
	shorttitle = {{SHAP} with {Python}},
	url = {https://adataodyssey.com/course/},
	abstract = {Theory behind Shapley values
Calculating SHAP values
SHAP aggregations
Custom SHAP plots
Interactions values
Categorical target variables and features
SHAP for computer vision},
	language = {English},
	journal = {SHAP with Python},
	author = {O'Sullivan, Conor},
	month = sep,
	year = {2024},
}

@book{porter_learn_2024,
	address = {Shelter Island, NY},
	title = {Learn {AI}-assisted {Python} programming: with {GitHub} {Copilot} and {ChatGPT}},
	isbn = {978-1-63343-778-4},
	shorttitle = {Learn {AI}-assisted {Python} programming},
	abstract = {Writing computer programs in Python just got a lot easier! Use AI-assisted coding tools like GitHub Copilot and ChatGPT to turn your ideas into applications faster than ever. AI has changed the way we write computer programs. With tools like Copilot and ChatGPT, you can describe what you want in plain English, and watch your AI assistant generate the code right before your eyes. It's perfect for beginners, or anyone who's struggled with the steep learning curve of traditional programming. Learn AI-Assisted Python Programming: With GitHub Copilot and ChatGPT is a hands-on beginner's guide that is written by two esteemed computer science university professors. It teaches you everything you need to start programming Python in an AI-first world. You'll hit the ground running, writing prompts that tell your AI-assistant exactly what you want your programs to do. Along the way, you'll pick up the essentials of Python programming and practice the higher-level thinking you'll need to create working apps for data analysis, automating tedious tasks, and even video games. The way people write computer programs has changed forever. Using GitHub Copilot, you describe in plain English what you want your program to do, and the AI generates it instantly. This book shows you how to create and improve Python programs using AI--even if you've never written a line of computer code before. Spend less time on the slow, low-level programming details and instead learn how an AI assistant can bring your ideas to life immediately. As you go, you'll even learn enough of the Python language to understand and improve what your AI assistant creates},
	language = {eng},
	publisher = {Manning},
	author = {Porter, Leo and Zingaro, Daniel},
	year = {2024},
}

@book{silver_inventory_2021,
	address = {Boca Raton, FL London New York, NY},
	edition = {Fourth edition, first issued in paperback},
	title = {Inventory and production management in supply chains},
	isbn = {978-1-03-217932-2},
	abstract = {Authored by a team of experts, the new edition of this bestseller presents practical techniques for managing inventory and production throughout supply chains. It covers the current context of inventory and production management, replenishment systems for managing individual inventories within a firm, managing inventory in multiple locations and firms, and production management. The book presents sophisticated concepts and solutions with an eye towards today's economy of global demand, cost-saving, and rapid cycles. It explains how to decrease working capital and how to deal with coordinating chains across boundaries},
	language = {eng},
	publisher = {CRC Press, Taylor \& Francis Group},
	author = {Silver, Edward A. and Pyke, David F. and Thomas, Douglas J.},
	year = {2021},
	annote = {Literaturangaben},
}

@book{vandeput_inventory_2020,
	address = {Berlin ; Boston},
	series = {Business \& economics},
	title = {Inventory optimization: models and simulations},
	isbn = {978-3-11-067391-3},
	shorttitle = {Inventory optimization},
	publisher = {De Gruyter},
	author = {Vandeput, Nicolas},
	year = {2020},
	keywords = {Business logistics, Inventory control},
}

@book{vandeput_data_2021,
	address = {Berlin ; Boston},
	edition = {Second edition},
	title = {Data science for supply chain forecasting},
	isbn = {978-3-11-067110-0},
	publisher = {De Gruyter},
	author = {Vandeput, Nicolas},
	year = {2021},
	note = {OCLC: on1246524462},
	keywords = {Business logistics, Data processing, Forecasting},
}

@book{vandeput_demand_2023,
	address = {Shelter Island, NY},
	title = {Demand forecasting best practices},
	isbn = {978-1-63343-809-5},
	abstract = {"An expert demand forecaster can help an organization avoid overproduction, reduce waste, and optimize inventory levels for a real competitive advantage. Demand Forecasting Best Practices teaches you how to become that virtuoso demand forecaster. This one-of-a-kind guide reveals forecasting tools, metrics, models, and stakeholder management techniques for delivering more effective supply chains. Everything you learn has been proven and tested in a live business environment. Discover author Nicolas Vandeput's original five step framework for demand planning excellence and learn how to tailor it to your own company's needs. Illustrations and real-world examples make each concept easy to understand and easy to follow. You'll soon be delivering accurate predictions that are driving major business value. Demand Forecasting Best Practices reveals forecasting tools, metrics, models, and stakeholder management techniques for managing your demand planning process efficiently and effectively. Everything you learn has been proven and tested in a live business environment. Discover author Nicolas Vandeput's original five step framework for demand planning excellence and learn how to tailor it to your own company's needs. Illustrations and real-world examples make each concept easy to understand and easy to follow. You'll soon be delivering accurate predictions that are driving major business value"--},
	publisher = {Manning Publications Co},
	author = {Vandeput, Nicolas},
	year = {2023},
	note = {OCLC: on1370328178},
	keywords = {Business logistics, Forecasting, Business forecasting, Demand (Economic theory), Demande (Théorie économique), Logistique (Organisation), Offre et demande, Prévision, Prévision commerciale, Supply and demand},
}

@misc{r_core_team_r_2024,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	shorttitle = {R {Stats}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {\{R Core Team\}},
	year = {2024},
}

@misc{hyndman__aut_fpp3_2024,
	title = {fpp3: {Data} for "{Forecasting}: {Principles} and {Practice}" (3rd {Edition})},
	copyright = {GPL-3},
	shorttitle = {fpp3},
	url = {https://cran.r-project.org/web/packages/fpp3/index.html},
	abstract = {All data sets required for the examples and exercises in the book "Forecasting: principles and practice" by Rob J Hyndman and George Athanasopoulos {\textless}https://OTexts.com/fpp3/{\textgreater}. All packages required to run the examples are also loaded. Additional data sets not used in the book are also included.},
	urldate = {2024-10-13},
	author = {Hyndman  [aut, Rob and cre and cph and Athanasopoulos, George and O'Hara-Wild, Mitchell and Palihawadana, Nuwani and Wickramasuriya, Shanika and RStudio},
	month = sep,
	year = {2024},
	keywords = {TimeSeries},
}

@misc{barrett_datatable_2024,
	title = {data.table: {Extension} of 'data.frame'},
	copyright = {MPL-2.0 {\textbar} file LICENSE},
	shorttitle = {data.table},
	url = {https://cran.r-project.org/web/packages/data.table/index.html},
	abstract = {Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, friendly and fast character-separated-value read/write. Offers a natural and flexible syntax, for faster development.},
	urldate = {2024-10-13},
	author = {Barrett, Tyson and Dowle, Matt and Srinivasan, Arun and Gorecki, Jan and Chirico, Michael and Hocking, Toby and Schwendinger, Benjamin and Stetsenko, Pasha and Short, Tom and Lianoglou, Steve and Antonyan, Eduard and Bonsch, Markus and Parsonage, Hugh and Ritchie, Scott and Ren, Kun and Tan, Xianying and Saporta, Rick and Seiskari, Otto and Dong, Xianghui and Lang, Michel and Iwasaki, Watal and Wenchel, Seth and Broman, Karl and Schmidt, Tobias and Arenburg, David and Smith, Ethan and Cocquemas, Francois and Gomez, Matthieu and Chataignon, Philippe and Blaser, Nello and Selivanov, Dmitry and Riabushenko, Andrey and Lee, Cheng and Groves, Declan and Possenriede, Daniel and Parages, Felipe and Toth, Denes and Yaramaz-David, Mus and Perumal, Ayappan and Sams, James and Morgan, Martin and Quinn, Michael and @javrucebo and @marc-outins and Storey, Roy and Saraswat, Manish and Jacob, Morgan and Schubmehl, Michael and Vaughan, Davis and Silvestri, Leonardo and Hester, Jim and Damico, Anthony and Freundt, Sebastian and Simons, David and Andrade, Elliott Sales de and Miller, Cole and Meldgaard, Jens Peder and Tlapak, Vaclav and Ushey, Kevin and Eddelbuettel, Dirk and Fischetti, Tony and Shilon, Ofek and Khotilovich, Vadim and Wickham, Hadley and Becker, Bennet and Haynes, Kyle and Kamgang, Boniface Christian and Delmarcell, Olivier and O'Brien, Josh and Mezquita, Dereck de and Czekanski, Michael and Shemetov, Dmitry and Jha, Nitish and Wu, Joshua and Giné-Vázquez, Iago and Chetia, Anirban and Amoakohene, Doris and Krylov, Ivan},
	month = oct,
	year = {2024},
	keywords = {ChemPhys, Finance, HighPerformanceComputing, TimeSeries, WebTechnologies},
}

@misc{wickham_ggplot2_2024,
	title = {ggplot2: {Create} {Elegant} {Data} {Visualisations} {Using} the {Grammar} of {Graphics}},
	copyright = {MIT + file LICENSE},
	shorttitle = {ggplot2},
	url = {https://cran.r-project.org/web/packages/ggplot2/index.html},
	abstract = {A system for 'declaratively' creating graphics, based on "The Grammar of Graphics". You provide the data, tell 'ggplot2' how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.},
	urldate = {2024-10-13},
	author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey and Brand, Teun van den and Posit and PBC},
	month = apr,
	year = {2024},
	keywords = {Phylogenetics, Spatial, TeachingStatistics},
}

@misc{debruine_glossary_2023,
	title = {glossary: {Glossaries} for {Markdown} and {Quarto} {Documents}},
	copyright = {CC BY 4.0},
	shorttitle = {glossary},
	url = {https://cran.r-project.org/web/packages/glossary/},
	abstract = {Add glossaries to markdown and quarto documents by tagging individual words. Definitions can be provided inline or in a separate file.},
	urldate = {2024-10-13},
	author = {DeBruine, Lisa},
	month = may,
	year = {2023},
}

@book{matthes_python_2019,
	address = {San Francisco, CA},
	edition = {2nd edition},
	title = {Python crash course: a hands-on, project-based introduction to programming},
	isbn = {978-1-59327-928-8},
	shorttitle = {Python crash course},
	publisher = {No Starch Press},
	author = {Matthes, Eric},
	year = {2019},
	keywords = {Object-oriented programming (Computer science), Python (Computer program language)},
	annote = {Includes index},
}

@book{ohara-wild2024,
	title = {fable: Forecasting Models for Tidy Time Series},
	author = {{O'Hara-Wild}, Mitchell and Hyndman, Rob and Wang, Earo and {implementation)}, {Gabriel Caceres (NNETAR} and Bergmeir, Christoph and Hensel, Tim-Gunnar and Hyndman, Timothy},
	year = {2024},
	month = {09},
	date = {2024-09-25},
	url = {https://cran.r-project.org/web/packages/fable/index.html}
}

@book{ohara-wild2024a,
	title = {feasts: Feature Extraction and Statistics for Time Series},
	author = {{O'Hara-Wild}, Mitchell and Hyndman, Rob and Wang, Earo and Cook, Di and {features)}, {Thiyanga Talagala (Correlation} and {method)}, {Leanne Chhay (Guerrero's}},
	year = {2024},
	month = {09},
	date = {2024-09-25},
	url = {https://cran.r-project.org/web/packages/feasts/index.html}
}

@book{hyndmanaut2024,
	title = {forecast: Forecasting Functions for Time Series and Linear Models},
	author = {{Hyndman  [aut}, Rob and cre,  and cph,  and Athanasopoulos, George and Bergmeir, Christoph and Caceres, Gabriel and Chhay, Leanne and Kuroptev, Kirill and {O'Hara-Wild}, Mitchell and Petropoulos, Fotios and Razbash, Slava and Wang, Earo and Yasmeen, Farah and Garza, Federico and Girolimetto, Daniele and Ihaka, Ross and R Core Team,  and Reid, Daniel and Shaub, David and Tang, Yuan and Wang, Xiaoqian and Zhou, Zhenyu},
	year = {2024},
	month = {06},
	date = {2024-06-20},
	url = {https://cran.r-project.org/web/packages/forecast/index.html}
}

@book{matthes2019,
	title = {Python crash course: a hands-on, project-based introduction to programming},
	author = {Matthes, Eric},
	year = {2019},
	date = {2019},
	publisher = {No Starch Press},
	edition = {2nd edition},
	address = {San Francisco, CA}
}

@book{nixtla/s2024,
	title = {Nixtla/statsforecast},
	year = {2024},
	month = {10},
	date = {2024-10-13},
	publisher = {Nixtla},
	url = {https://github.com/Nixtla/statsforecast},
	note = {original-date: 2021-11-24T02:19:14Z}
}

@book{nixtla/m2024,
	title = {Nixtla/mlforecast},
	year = {2024},
	month = {10},
	date = {2024-10-12},
	publisher = {Nixtla},
	url = {https://github.com/Nixtla/mlforecast},
	note = {original-date: 2021-04-26T20:58:42Z}
}

@misc{nixtla/h,
	title = {Nixtla/hierarchicalforecast: Probabilistic Hierarchical forecasting 👑 with statistical and econometric methods.},
	url = {https://github.com/Nixtla/hierarchicalforecast}
}

@book{nixtla/t2024,
	title = {Nixtla/tsfeatures},
	year = {2024},
	month = {10},
	date = {2024-10-08},
	publisher = {Nixtla},
	url = {https://github.com/Nixtla/tsfeatures},
	note = {original-date: 2019-11-20T17:29:55Z}
}

@misc{wickham,
	title = {R for Data Science (2e)},
	author = {Wickham, Hadley},
	url = {https://r4ds.hadley.nz/}
}
